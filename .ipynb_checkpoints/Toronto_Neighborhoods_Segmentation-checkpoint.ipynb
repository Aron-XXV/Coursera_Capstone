{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First phase notebook: Segmenting and Clustering Neighborhoods in Toronto\n",
    "TOC to be completed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st step, importing the dataset\n",
    "in this step the dataset is read using pandas library. Then its 5 first row printed. The desired table is stored in the first table of url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "df = pd.read_html(url)[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd step, cleaning and forming the dataset\n",
    "According to the provided instruction, unique postal codes are analysed. Becasue the number of unique codes are the same of the current recodes, there is no need of merging or combining rows. In the next stage, Borough without assigned values are deleted. Then neigbourhoods without assigned value are investigated. Becasue there are no rows with such a specification, no cell is replaced with its borough. Finally, the shape of the dataset is printed and the last 5 rows are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and forming the dataset\n",
    "print('The dataset includes {} records with {} unique postal codes \\n'.format(len(df) , len(df['Postal Code'].unique())))\n",
    "# igonring cells that Borough is not assigned\n",
    "df = df[df['Borough'] != 'Not assigned']\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "print('Aftering deleting rows without assigned boroughs, the number of records reduced to {} \\n'.format(len(df)))\n",
    "# assigning Borough to Neighbourhood where Neighbourhood is 'Not assigned'\n",
    "n_na_neighbour = df['Neighbourhood'][df['Neighbourhood'] == 'Not assigned'].count()\n",
    "print('After correcting NA boroughs, {} neighbourhoods found without assigned value \\n'.format(n_na_neighbour))\n",
    "print('the final shape of the dataset is {} \\n'.format(df.shape))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd step, transforming the database\n",
    "In the next phase of the project, each neighbourhood's coordinates should be found. So, having their name stored in a single cell is not desirable. The ideal form of dataset is having neighbourhood name in a cell, preferably set as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataset setting each neighbourhood in one row\n",
    "dfn = pd.DataFrame(columns = ['Postal Code', 'Borough', 'Neighbourhood'])\n",
    "for nn in range(0, len(df) - 1):\n",
    "    borough = df['Borough'].iloc[nn]\n",
    "    post_code = df['Postal Code'].iloc[nn]\n",
    "    neighbourhoods = df['Neighbourhood'].iloc[nn].split(', ')\n",
    "    for neighbourhood in neighbourhoods: \n",
    "        dfn_add = pd.DataFrame({'Borough': [borough], 'Postal Code': [post_code], 'Neighbourhood' : [neighbourhood]})\n",
    "        dfn = dfn.append(dfn_add, ignore_index=True)\n",
    "print('the dataset includes {} neighbourhoods \\n'.format(len(dfn)))\n",
    "dfn.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th step, finding coordinates\n",
    "According to the provided instructions of the assignment, geocoder is used in a while loop to find the corresponding long/lat of each rows in the newly transformed dataset. Unfortunately, it has not ended to any plausible result. So, I used instead geopy which made it possible. Two columns have been added to the new dataset.\n",
    "there are several differences which made the code into work:\n",
    "1. using geopy, Nominatim\n",
    "2. passing GeocoderTimedOut for avoiding errors of timing out\n",
    "3. setting a search limit for a neighbourhood\n",
    "4. using sleep of 1 sec for avoiding server runtime limit block\n",
    "5. passing a random symbolic password\n",
    "6. random ordering of address \n",
    "<br>\n",
    "\n",
    "Finally, geocoder fails to locate some neibourhoods. These records should be handled manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_geocode(address):\n",
    "    geopy = Nominatim(user_agent=\"aron.shirazi@gmail.com\")\n",
    "    try:\n",
    "        sleep(1)\n",
    "        return geopy.geocode(address)\n",
    "    except GeocoderTimedOut:\n",
    "        return do_geocode(address)\n",
    "\n",
    "dfn['latitude'] = 'NA'\n",
    "dfn['longitude'] = 'NA'\n",
    "max_try = 10\n",
    "for nn in range(0, len(dfn)):\n",
    "    neighbourhood = dfn['Neighbourhood'].iloc[nn]\n",
    "    location = None\n",
    "    count = 0\n",
    "    while (location == None) & (count < max_try):\n",
    "        password = ''.join(random.choice(['#', '$', '%', '@', '*', '-', '&', '~', '!']) for i in range(8))\n",
    "        address_list = [neighbourhood, 'Toronto', 'Ontario', password]\n",
    "        order = ''.join(random.sample(['0', '1', '2', '3'], 4))\n",
    "        n0 = int(order[0]); n1 = int(order[1]); n2 = int(order[2]); n3 = int(order[3])\n",
    "        address = '{}, {}, {}, {}'.format(address_list[n0], address_list[n1], address_list[n2], address_list[n3])\n",
    "        location = do_geocode(address)\n",
    "        count += 1\n",
    "    if location is not None:\n",
    "        print('{}, coordinates found for {}'.format(nn, neighbourhood))\n",
    "        dfn['latitude'].iloc[nn] = location.latitude\n",
    "        dfn['longitude'].iloc[nn] = location.longitude\n",
    "    else:\n",
    "        print('{}, coordinates not found for {}'.format(nn, neighbourhood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding unlocated neighbourhoods to set the m manually\n",
    "dfn['latitude'][~dfn['latitude'].apply(np.isreal)] = '0'\n",
    "dfn['longitude'][~dfn['longitude'].apply(np.isreal)] = '0'\n",
    "dfn['latitude'] = dfn['latitude'].astype('float', errors='ignore')\n",
    "dfn['longitude'] = dfn['longitude'].astype('float', errors='ignore')\n",
    "dfn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_csv('Geospatial_Coordinates.csv')\n",
    "for nn in dfn[dfn['longitude'] == 0].index:\n",
    "    dfn['latitude'].iloc[nn] = float(dfo['Latitude'][dfo['Postal Code'] == dfn['Postal Code'].iloc[nn]])\n",
    "    dfn['longitude'].iloc[nn] = float(dfo['Longitude'][dfo['Postal Code'] == dfn['Postal Code'].iloc[nn]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the center of map for illustration purpuse\n",
    "df_loc = dfn[dfn['Neighbourhood'] != 'South Niagara'] # South Niagra is far away and makes our analysis inefficient so it is omitted\n",
    "center_lat = df_loc['latitude'].mean()\n",
    "center_lon = df_loc['longitude'].mean()\n",
    "# to set boundaries of folium\n",
    "lat_min = df_loc['latitude'].min()\n",
    "lat_max = df_loc['latitude'].max()\n",
    "lon_min = df_loc['longitude'].min()\n",
    "lon_max = df_loc['longitude'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_toronto = folium.Map(location=[center_lat, center_lon], width=750, height=500)\n",
    "map_toronto.fit_bounds([[lat_min, lon_min], [lat_max, lon_max]])\n",
    "# add markers to map\n",
    "for lat, lng, label in zip(df_loc['latitude'], df_loc['longitude'], df_loc['Neighbourhood']):\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto)  \n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Foursquare Credentials and Version\n",
    "# importing credentials\n",
    "load_dotenv()\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "CLIENT_ID = os.getenv(\"Foursquare_CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"Foursquare_CLIENT_SECRET\")\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']\n",
    "\n",
    "def find_venue(lat, lon, limit = 100, radius = 500):\n",
    "    url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    lat, \n",
    "    lon, \n",
    "    radius, \n",
    "    limit)\n",
    "    results = requests.get(url).json()\n",
    "    venues = results['response']['groups'][0]['items']\n",
    "    nearby_venues = None\n",
    "    if len(venues) > 0:\n",
    "        nearby_venues = pd.json_normalize(venues) # flatten JSON\n",
    "        # filter columns\n",
    "        filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "        nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "        # filter the category for each row\n",
    "        nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "        # clean columns\n",
    "        nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "    return nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues = pd.DataFrame(columns = ['name', 'categories', 'lat', 'lng'])\n",
    "nn = 0\n",
    "for name, lat, lng in zip(df_loc['Neighbourhood'], df_loc['latitude'], df_loc['longitude']):\n",
    "    df_tr = find_venue(lat, lon)\n",
    "    if df_tr is None: \n",
    "        len_found = 0 \n",
    "    else: \n",
    "        len_found = len(df_tr)\n",
    "        df_tr['neighbourhood'] = name\n",
    "    print('{}, venues of {} explored at lat: {} and long: {}, with {} venues'.format(nn, name, lat, lng, len_found))\n",
    "    df_venues = pd.concat([df_venues, df_tr])\n",
    "    nn += 1\n",
    "df_venues.reset_index(inplace = True, drop = True)\n",
    "print('venues of Toronto are explored, the dataset shape is {} \\n'.format(df_venues.shape))\n",
    "df_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues.groupby('neighbourhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories \\n'.format(len(df_venues['categories'].unique())))\n",
    "print('There are {} uniques venues \\n'.format(len(df_venues['name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
